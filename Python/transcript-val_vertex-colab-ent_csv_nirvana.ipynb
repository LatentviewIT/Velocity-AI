{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## Main Code"
      ],
      "metadata": {
        "id": "bjU7yc3ANkH_"
      },
      "id": "bjU7yc3ANkH_"
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 0. Libraries"
      ],
      "metadata": {
        "id": "-nOP2Av89eWT"
      },
      "id": "-nOP2Av89eWT"
    },
    {
      "cell_type": "code",
      "source": [
        "import vertexai\n",
        "from vertexai.generative_models import GenerativeModel, GenerationConfig\n",
        "from google.cloud import bigquery\n",
        "from google.api_core.exceptions import GoogleAPIError\n",
        "import json\n",
        "import time\n",
        "import re\n",
        "from datetime import datetime, timedelta\n",
        "from typing import List, Dict, Any, Optional"
      ],
      "metadata": {
        "id": "edbUQVlo9cqc"
      },
      "id": "edbUQVlo9cqc",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1. Configuration & Naming Standards"
      ],
      "metadata": {
        "id": "KKhEzA4C9hzJ"
      },
      "id": "KKhEzA4C9hzJ"
    },
    {
      "cell_type": "code",
      "source": [
        "# ==========================================\n",
        "# 1. CONFIGURATION & NAMING STANDARDS\n",
        "# ==========================================\n",
        "\n",
        "PROJECT_ID = \"project-nirvana-405904\"  # <--- REPLACE THIS\n",
        "LOCATION = \"us-central1\"\n",
        "\n",
        "PROJECT_TAG = \"csv\"\n",
        "SCRIPT_VERSION = \"002\"\n",
        "SOURCE_VERSION = \"006\" # <--- CHANGE THIS TO THE CURRENT TRANSCRIPTIONS TABLE VERSION\n",
        "\n",
        "# Single Table Architecture\n",
        "DATASET_ID = f\"vel_{PROJECT_TAG}_schema\"\n",
        "TARGET_TABLE = f\"vel_{PROJECT_TAG}_synthetic_transcripts_{SOURCE_VERSION}\"\n",
        "STAGING_TABLE = f\"{TARGET_TABLE}_staging_temp\" # Temporary table for MERGE\n",
        "\n",
        "# For merge operator (updating rows)\n",
        "BATCH_SIZE = 200\n",
        "\n",
        "# Initialize Vertex AI\n",
        "vertexai.init(project=PROJECT_ID, location=LOCATION)\n",
        "model = GenerativeModel(\"gemini-2.5-flash\")\n",
        "\n",
        "# Initialize BigQuery\n",
        "bq_client = bigquery.Client(project=PROJECT_ID)"
      ],
      "metadata": {
        "id": "3m1YdXlR9iNx"
      },
      "id": "3m1YdXlR9iNx",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2. Validator System Promopt (Strict Auditor)"
      ],
      "metadata": {
        "id": "JZkNBYaT9m8n"
      },
      "id": "JZkNBYaT9m8n"
    },
    {
      "cell_type": "code",
      "source": [
        "# ==========================================\n",
        "# 2. VALIDATOR SYSTEM PROMPT (Strict Auditor)\n",
        "# ==========================================\n",
        "\n",
        "VALIDATOR_SYSTEM_PROMPT = \"\"\"\n",
        "You are an automated **Agent Validator**: a strict, forensic auditor for synthetic conversational transcripts between:\n",
        " - Agent A: \"YouTube Strategic Partner Manager\" (SPM)\n",
        " - Agent B: \"YouTube Creator\"\n",
        "\n",
        "Your job: read exactly one JSON payload (transcript + metadata) provided as the user message content, evaluate it against the rules below, and output **only** a single JSON object that strictly follows the JSON Output Schema.\n",
        "\n",
        "REQUIREMENTS\n",
        "1. Parse input JSON; expect keys: \"transcript\", \"meta\", \"conversation_id\".\n",
        "2. Run the following detectors:\n",
        "   A. Hallucination Detector (PRODUCT & POLICY PROMISES): Flag impossible outcomes (e.g., \"I will manually remove a strike in 5 minutes\").\n",
        "   B. Character Coherence Detector: Flag mismatch (e.g., SPM using insults).\n",
        "   C. Policy Accuracy Detector: Check for obviously incorrect instructions.\n",
        "   D. Conversational Realism Detector (Human-ness): Score naturalness (1.0-5.0). Penalize \"Robot-talk\", reward \"Human noise\".\n",
        "   E. Structural Narrative Detector: Score logical start -> problem -> resolution flow (1.0-5.0).\n",
        "\n",
        "SCORING RULES:\n",
        "- Evaluate the three dimensions on a scale of 1.0 to 5.0.\n",
        "- Set hallucination_flag to true if a hallucination/policy error is detected, otherwise false.\n",
        "\n",
        "JSON OUTPUT SCHEMA (MANDATORY):\n",
        "{\n",
        "  \"hallucination_flag\": <boolean>,\n",
        "  \"detected_errors\": [<string>, ...],\n",
        "  \"correction_suggestions\": [<string>, ...],\n",
        "  \"Realism_Human\": <float>,\n",
        "  \"Policy_Precision\": <float>,\n",
        "  \"Narrative_Coherence\": <float>\n",
        "}\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "rZG3lSHy9nL-"
      },
      "id": "rZG3lSHy9nL-",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3. Helper Functions"
      ],
      "metadata": {
        "id": "UjF1In8u9qAM"
      },
      "id": "UjF1In8u9qAM"
    },
    {
      "cell_type": "code",
      "id": "niFtBbXQkiRSCB49okHSalaD",
      "metadata": {
        "tags": [],
        "id": "niFtBbXQkiRSCB49okHSalaD"
      },
      "source": [
        "# ==========================================\n",
        "# 3. HELPER FUNCTIONS\n",
        "# ==========================================\n",
        "\n",
        "def parse_raw_transcript(raw_data: Any) -> List[Dict[str, Any]]:\n",
        "    \"\"\"\n",
        "    Parses the raw data from BQ into the list structure required by the Validator.\n",
        "    Since the upstream Generator now outputs clean JSON, this function primarily\n",
        "    handles native Python lists, but retains fallback logic for legacy string records.\n",
        "    \"\"\"\n",
        "    # 1. Fast path: If BQ already handed us a parsed list (Native JSON column), return it directly.\n",
        "    if isinstance(raw_data, list):\n",
        "        return raw_data\n",
        "\n",
        "    # 2. Fallback: If it's a string (legacy data or upstream failure), apply cleaning.\n",
        "    if isinstance(raw_data, str):\n",
        "        clean_text = raw_data.strip()\n",
        "\n",
        "        # Remove Markdown fences if present\n",
        "        clean_text = re.sub(r\"^```(?:json)?\\s*\", \"\", clean_text)\n",
        "        clean_text = re.sub(r\"\\s*```$\", \"\", clean_text)\n",
        "\n",
        "        # Fix double-escaped CSV quotes\n",
        "        if '\"\"role\"\"' in clean_text:\n",
        "            clean_text = clean_text.replace('\"\"', '\"').strip('\"')\n",
        "\n",
        "        parsed_json = None\n",
        "        try:\n",
        "            parsed_json = json.loads(clean_text)\n",
        "        except json.JSONDecodeError:\n",
        "            pass\n",
        "\n",
        "        # Handle the \"Split-Object Bug\" from older LLM generations\n",
        "        if isinstance(parsed_json, list):\n",
        "            normalized_dialogue = []\n",
        "            buffer_role = None\n",
        "\n",
        "            for item in parsed_json:\n",
        "                if \"role\" in item and \"content\" in item:\n",
        "                    r = str(item[\"role\"]).strip()\n",
        "                    c = str(item[\"content\"]).strip()\n",
        "\n",
        "                    if r.lower() in [\"role\", '\"role\"']:\n",
        "                        buffer_role = c\n",
        "                    elif r.lower() in [\"content\", '\"content\"']:\n",
        "                        if buffer_role:\n",
        "                            normalized_dialogue.append({\"role\": buffer_role, \"content\": c})\n",
        "                            buffer_role = None\n",
        "                        else:\n",
        "                            normalized_dialogue.append({\"role\": \"Unknown\", \"content\": c})\n",
        "                    else:\n",
        "                        normalized_dialogue.append({\"role\": r, \"content\": c})\n",
        "\n",
        "            if normalized_dialogue:\n",
        "                return normalized_dialogue\n",
        "\n",
        "        # Ultimate fallback: Line-by-line parsing if JSON is completely broken\n",
        "        dialogue = []\n",
        "        for line in raw_data.splitlines():\n",
        "            line = line.replace('\"\"', '\"').strip('\"')\n",
        "            parts = line.split(\":\", 1)\n",
        "            if len(parts) == 2:\n",
        "                role_cand = parts[0].strip().replace('\"', '')\n",
        "                content_cand = parts[1].strip().replace('\"', '')\n",
        "                final_role = \"Unknown\"\n",
        "\n",
        "                if \"SPM\" in role_cand.upper():\n",
        "                    final_role = \"SPM\"\n",
        "                if \"CREATOR\" in role_cand.upper():\n",
        "                    final_role = \"Creator\"\n",
        "\n",
        "                if final_role != \"Unknown\":\n",
        "                    dialogue.append({\"role\": final_role, \"content\": content_cand})\n",
        "\n",
        "        return dialogue\n",
        "\n",
        "    # If we receive None or an unexpected type\n",
        "    return []\n",
        "\n",
        "def clean_json_response(response_text: str) -> Dict[str, Any]:\n",
        "    \"\"\"\n",
        "    Sanitizes LLM output to ensure valid JSON parsing.\n",
        "    \"\"\"\n",
        "    try:\n",
        "        cleaned = re.sub(r\"^```(?:json)?\\s*\", \"\", response_text).strip()\n",
        "        cleaned = re.sub(r\"\\s*```$\", \"\", cleaned).strip()\n",
        "        return json.loads(cleaned)\n",
        "    except Exception as e:\n",
        "        print(f\"‚ùå JSON Parsing Error: {e}\")\n",
        "        return {\n",
        "            \"hallucination_flag\": True,\n",
        "            \"detected_errors\": [\"Validator Output Malformed\"],\n",
        "            \"Realism_Human\": 1.0,\n",
        "            \"Policy_Precision\": 1.0,\n",
        "            \"Narrative_Coherence\": 1.0\n",
        "        }"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 4. Core Logic: The Validator Class"
      ],
      "metadata": {
        "id": "_drXH0CD9s-b"
      },
      "id": "_drXH0CD9s-b"
    },
    {
      "cell_type": "code",
      "source": [
        "# ==========================================\n",
        "# 4. Core Logic: The Validator Class\n",
        "# ==========================================\n",
        "\n",
        "class TranscriptValidator:\n",
        "    def __init__(self):\n",
        "        self.processed_count = 0\n",
        "        self.validation_results = []\n",
        "\n",
        "    def validate_row(self, row) -> Dict[str, Any]:\n",
        "        \"\"\"\n",
        "        Takes a BigQuery Row object, runs validation, returns the result dict.\n",
        "        \"\"\"\n",
        "        conv_id = row[\"conversation_id\"]\n",
        "        raw_text = row[\"raw_transcript\"]\n",
        "\n",
        "        # 1. Parse Input\n",
        "        transcript_data = parse_raw_transcript(raw_text)\n",
        "\n",
        "        # 2. Construct Payload\n",
        "        payload = {\n",
        "            \"conversation_id\": conv_id,\n",
        "            \"transcript\": transcript_data,\n",
        "            \"meta\": {\n",
        "                \"role_label\": {\"A\": \"SPM\", \"B\": \"Creator\"}\n",
        "            }\n",
        "        }\n",
        "\n",
        "        # 3. Call Gemini\n",
        "        try:\n",
        "            prompt = f\"{VALIDATOR_SYSTEM_PROMPT}\\n\\nUSER INPUT:\\n```json\\n{json.dumps(payload)}\\n```\"\n",
        "\n",
        "            response = model.generate_content(\n",
        "                prompt,\n",
        "                generation_config=GenerationConfig(\n",
        "                    temperature=0.0,\n",
        "                    response_mime_type=\"application/json\"\n",
        "                )\n",
        "            )\n",
        "\n",
        "            # 4. Process Output\n",
        "            audit_report = clean_json_response(response.text)\n",
        "\n",
        "            # 5. PYTHON CALCULATES MATH AND LOGIC (Safe from LLM Hallucinations)\n",
        "            realism = float(audit_report.get(\"Realism_Human\") or 1.0)\n",
        "            policy = float(audit_report.get(\"Policy_Precision\") or 1.0)\n",
        "            narrative = float(audit_report.get(\"Narrative_Coherence\") or 1.0)\n",
        "            hallucination = bool(audit_report.get(\"hallucination_flag\", False))\n",
        "\n",
        "            # Weighted average\n",
        "            base_score = round((realism * 0.35) + (policy * 0.40) + (narrative * 0.25), 2)\n",
        "\n",
        "            # Penalty\n",
        "            final_score = base_score - 1.0 if hallucination else base_score\n",
        "            final_score = max(1.0, round(final_score, 2))\n",
        "\n",
        "            # Validation logic\n",
        "            is_valid = (final_score >= 3.2) and (not hallucination)\n",
        "\n",
        "            # 6. Return Record (Ready for MERGE)\n",
        "            return {\n",
        "                \"conversation_id\": conv_id,\n",
        "                \"is_valid\": is_valid,\n",
        "                \"quality_score\": final_score,\n",
        "                \"hallucination_flag\": hallucination,\n",
        "                \"validation_report\": audit_report,\n",
        "                \"audit_timestamp\": datetime.utcnow().isoformat()\n",
        "            }\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"‚ö†Ô∏è Error validating {conv_id}: {str(e)}\")\n",
        "            return None"
      ],
      "metadata": {
        "id": "UQjfNoRr9tOj"
      },
      "id": "UQjfNoRr9tOj",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 5. BigQuery Upload"
      ],
      "metadata": {
        "id": "NzyRo15Q9w1Z"
      },
      "id": "NzyRo15Q9w1Z"
    },
    {
      "cell_type": "code",
      "source": [
        "# ==========================================\n",
        "# 5. BIGQUERY UPLOAD (IN-PLACE UPDATE VIA MERGE)\n",
        "# ==========================================\n",
        "\n",
        "def fetch_pending_transcripts(limit: int = 100):\n",
        "    \"\"\"\n",
        "    Fetches rows from the single table where validation is missing.\n",
        "    \"\"\"\n",
        "    query = f\"\"\"\n",
        "        SELECT\n",
        "            conversation_id,\n",
        "            raw_transcript\n",
        "        FROM `{PROJECT_ID}.{DATASET_ID}.{TARGET_TABLE}`\n",
        "        WHERE is_valid IS NULL OR validation_report IS NULL\n",
        "        LIMIT {limit}\n",
        "    \"\"\"\n",
        "    print(\"üì• Fetching pending transcripts for validation...\")\n",
        "    return bq_client.query(query).result()\n",
        "\n",
        "def update_bq_via_merge(results: List[Dict[str, Any]]):\n",
        "    \"\"\"\n",
        "    Uses a temporary staging table to bulk UPDATE the main table (MERGE).\n",
        "    Avoids DML Quota limits.\n",
        "    \"\"\"\n",
        "    if not results:\n",
        "        return\n",
        "\n",
        "    staging_ref = f\"{PROJECT_ID}.{DATASET_ID}.{STAGING_TABLE}\"\n",
        "    target_ref = f\"{PROJECT_ID}.{DATASET_ID}.{TARGET_TABLE}\"\n",
        "\n",
        "    # 1. Load results into temporary staging table\n",
        "    job_config = bigquery.LoadJobConfig(\n",
        "        write_disposition=\"WRITE_TRUNCATE\", # Replace if exists from previous failed run\n",
        "        schema=[\n",
        "            bigquery.SchemaField(\"conversation_id\", \"STRING\"),\n",
        "            bigquery.SchemaField(\"is_valid\", \"BOOLEAN\"),\n",
        "            bigquery.SchemaField(\"quality_score\", \"FLOAT\"),\n",
        "            bigquery.SchemaField(\"hallucination_flag\", \"BOOLEAN\"),\n",
        "            bigquery.SchemaField(\"validation_report\", \"JSON\"),\n",
        "            bigquery.SchemaField(\"audit_timestamp\", \"TIMESTAMP\"),\n",
        "        ]\n",
        "    )\n",
        "\n",
        "    try:\n",
        "        print(f\"üì¶ Loading {len(results)} records to temporary staging table...\")\n",
        "        job = bq_client.load_table_from_json(results, staging_ref, job_config=job_config)\n",
        "        job.result()\n",
        "\n",
        "        # 2. Execute MERGE query to update TARGET_TABLE\n",
        "        merge_query = f\"\"\"\n",
        "            MERGE `{target_ref}` T\n",
        "            USING `{staging_ref}` S\n",
        "            ON T.conversation_id = S.conversation_id\n",
        "            WHEN MATCHED THEN\n",
        "              UPDATE SET\n",
        "                T.is_valid = S.is_valid,\n",
        "                T.quality_score = S.quality_score,\n",
        "                T.hallucination_flag = S.hallucination_flag,\n",
        "                T.validation_report = S.validation_report,\n",
        "                T.audit_timestamp = S.audit_timestamp\n",
        "        \"\"\"\n",
        "        print(\"üîÑ Executing MERGE operation to update main table...\")\n",
        "        bq_client.query(merge_query).result()\n",
        "\n",
        "        # 3. Clean up (Drop staging table)\n",
        "        bq_client.delete_table(staging_ref, not_found_ok=True)\n",
        "        print(f\"‚úÖ Successfully updated {len(results)} rows and cleaned up staging.\")\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"‚ùå BigQuery update failed: {e}\")"
      ],
      "metadata": {
        "id": "gb8_PkXH9xBo"
      },
      "id": "gb8_PkXH9xBo",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Run Main"
      ],
      "metadata": {
        "id": "e4HKuRwCNt3c"
      },
      "id": "e4HKuRwCNt3c"
    },
    {
      "cell_type": "code",
      "source": [
        "if __name__ == \"__main__\":\n",
        "    import sys # Import needed for clean exit\n",
        "    start_time = time.perf_counter()\n",
        "\n",
        "    print(\"üöÄ Starting Validator Pipeline (In-Place Update Strategy)...\")\n",
        "\n",
        "    # 1. Instantiate Validator\n",
        "    validator = TranscriptValidator()\n",
        "\n",
        "    # 2. Fetch Data (Unvalidated rows only)\n",
        "    rows = fetch_pending_transcripts(limit=BATCH_SIZE)\n",
        "    rows_list = list(rows)\n",
        "\n",
        "    if not rows_list:\n",
        "        print(\"üò¥ No pending transcripts found. Everything is up to date.\")\n",
        "        sys.exit()\n",
        "\n",
        "    print(f\"üîç Found {len(rows_list)} new transcripts to validate.\")\n",
        "\n",
        "    batch_results = []\n",
        "\n",
        "    # 3. Iterate and Validate\n",
        "    for row in rows_list:\n",
        "        result = validator.validate_row(row)\n",
        "\n",
        "        if result:\n",
        "            batch_results.append(result)\n",
        "\n",
        "            # Logging\n",
        "            status_icon = \"‚úÖ\" if result[\"is_valid\"] else \"‚ùå\"\n",
        "            print(f\"{status_icon} [{row['conversation_id']}] Score: {result['quality_score']}\")\n",
        "\n",
        "        # Rate Limiting\n",
        "        time.sleep(0.5)\n",
        "\n",
        "    end_time_sd = time.perf_counter()\n",
        "\n",
        "    # 4. Upload Results (Using MERGE)\n",
        "    if batch_results:\n",
        "        update_bq_via_merge(batch_results)\n",
        "\n",
        "    end_time = time.perf_counter()\n",
        "\n",
        "    print(\"üèÅ Pipeline finished successfully.\")\n",
        "\n",
        "    duration_sd = str(timedelta(seconds=end_time_sd - start_time))\n",
        "    duration_bq = str(timedelta(seconds=end_time - end_time_sd))\n",
        "    duration_total = str(timedelta(seconds=end_time - start_time))\n",
        "\n",
        "    print(f\"Validation execution time: {duration_sd}\")\n",
        "    print(f\"Upload execution time: {duration_bq}\")\n",
        "    print(f\"Total execution time: {duration_total}\")"
      ],
      "metadata": {
        "id": "RZtiauz0Nwwg",
        "collapsed": true
      },
      "id": "RZtiauz0Nwwg",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "In average it takes:\n",
        "\n",
        "~11.5 seconds to validate a transcription\n",
        "\n",
        "~6 seconds to update the BigQuery table"
      ],
      "metadata": {
        "id": "SB4W8BMaGt3w"
      },
      "id": "SB4W8BMaGt3w"
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "df_results = pd.DataFrame(batch_results)\n",
        "print(\"Not Valid: \", df_results[df_results['is_valid'] == False].shape[0])\n",
        "print(\"Valid: \", df_results[df_results['is_valid'] == True].shape[0])\n",
        "print(\"Porcentaje de transcripciones correctas: \", (df_results[df_results['is_valid'] == True].shape[0]/df_results.shape[0])*100, \"%\")"
      ],
      "metadata": {
        "id": "CHkl7WZPMJn6"
      },
      "id": "CHkl7WZPMJn6",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.10"
    },
    "colab": {
      "provenance": [],
      "name": "vel_csv_transcription_validator_002",
      "toc_visible": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
